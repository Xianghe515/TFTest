{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 어텐션\n",
    "# seq2seq\n",
    "\n",
    "# 라이브러리\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 전처리를 위한 함수 정의\n",
    "def unicode_to_ascii(s):        # 유니코드를 아스키로 변환\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    " \n",
    "def preprocess_sentence(w):     # 문장 전처리\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> May I borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf Puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "# 전처리 내용 테스트\n",
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    " \n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    " \n",
    "    return zip(*word_pairs)\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    " \n",
    "def tokenize(lang):   # 문장의 토큰화\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    " \n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    " \n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    " \n",
    "  return tensor, lang_tokenizer\n",
    " \n",
    "def load_dataset(path, num_examples=None):    # 입력/출력(english, spanish) 쌍 만들기\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    " \n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    " \n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset('./data/spa.txt', num_examples)\n",
    " \n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    " \n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분석을 준비하기 앞서 하이퍼파라미터들을 정의\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    " \n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "# 데이터 분석을 위한 데이터셋 준비\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 네트워크\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    " \n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    " \n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))  # 은닉층 초기화\n",
    " \n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 구현\n",
    "class EDAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(EDAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    " \n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1) #1 텐서의 원하는 위치에 차원 추가\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis))) #2 배치 크기, 시퀀스 최대 길이 1\n",
    " \n",
    "        attention_weights = tf.nn.softmax(score, axis=1) # 어텐션 가중치(attention_weight)의 형태는 (배치크기, 시퀸스 최대 길이, 1)이 됩니다.\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1) # 컨텍스트 벡터(context_vector)의 형태는 (배치크기, 은닉층 크기)입니다.\n",
    "        return context_vector, attention_weights \n",
    "attention_layer = EDAttention(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 네트워크\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = EDAttention(self.dec_units) #어텐션 적용\n",
    " \n",
    "    def call(self, x, hidden, enc_output):  # 인코더 출력(enc_output)형태는 (배치크기, 시퀸스 최대 길이, 은닉층 크기)입니다.\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)  # 임베딩층을 통과한 후 x의 형태는 (배치크기, 1, 임베딩 차원)입니다.\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)  # 병합된 벡터를 GRU로 보냅니다.\n",
    "        output = tf.reshape(output, (-1, output.shape[2])) # 출력 형태는 (배치크기x1, 은닉층 크기)입니다..\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights\n",
    " \n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련을 위한 옵티마이저와 손실함수 정의\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    " \n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1cfe5a67d40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델의 저장과 복원을 위한 체크포인트 설정\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder, epoch=tf.Variable(1))\n",
    "\n",
    "# 체크포인트 로딩 코드 - 모델 훈련하는 함수 내에서 실행\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 훈련시키기 위한 함수 정의\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "# 체크포인트 로딩 코드\n",
    "  # checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "  with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        for t in range(1, targ.shape[1]): # 대상 단어를 입력으로 사용\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output) # 인코더 출력(enc_output)을 디코더로 보냄\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "  batch_loss = (loss / int(targ.shape[1]))  # 손실/오차 계산\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables)) \n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.5423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (inp, targ)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mtake(steps_per_epoch)):\n\u001b[1;32m---> 11\u001b[0m   batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m   total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m     14\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[29], line 6\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(inp, targ, enc_hidden)\u001b[0m\n\u001b[0;32m      3\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 체크포인트 로딩 코드\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m   \u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m      8\u001b[0m         enc_output, enc_hidden \u001b[38;5;241m=\u001b[39m encoder(inp, enc_hidden)\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:2732\u001b[0m, in \u001b[0;36mCheckpoint.restore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2729\u001b[0m   save_path \u001b[38;5;241m=\u001b[39m path_helpers\u001b[38;5;241m.\u001b[39mget_variables_path(save_path)\n\u001b[0;32m   2731\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2732\u001b[0m   status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2733\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m   2734\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()  \u001b[38;5;66;03m# Ensure restore operations have completed.\u001b[39;00m\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:2595\u001b[0m, in \u001b[0;36mCheckpoint.read\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2593\u001b[0m   save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(save_path)\n\u001b[0;32m   2594\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;129;01mor\u001b[39;00m checkpoint_options\u001b[38;5;241m.\u001b[39mCheckpointOptions()\n\u001b[1;32m-> 2595\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2596\u001b[0m metrics\u001b[38;5;241m.\u001b[39mAddCheckpointReadDuration(\n\u001b[0;32m   2597\u001b[0m     api_label\u001b[38;5;241m=\u001b[39m_CHECKPOINT_V2,\n\u001b[0;32m   2598\u001b[0m     microseconds\u001b[38;5;241m=\u001b[39m_get_duration_microseconds(start_time, time\u001b[38;5;241m.\u001b[39mtime()))\n\u001b[0;32m   2599\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:1503\u001b[0m, in \u001b[0;36mTrackableSaver.restore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1492\u001b[0m object_graph_proto\u001b[38;5;241m.\u001b[39mParseFromString(object_graph_string)\n\u001b[0;32m   1493\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _CheckpointRestoreCoordinator(\n\u001b[0;32m   1494\u001b[0m     object_graph_proto\u001b[38;5;241m=\u001b[39mobject_graph_proto,\n\u001b[0;32m   1495\u001b[0m     save_path\u001b[38;5;241m=\u001b[39msave_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1501\u001b[0m     saveables_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_saveables_cache)\n\u001b[0;32m   1502\u001b[0m \u001b[43mrestore_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCheckpointPosition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m-> 1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;66;03m# Attached dependencies are not attached to the root, so should be restored\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;66;03m# separately.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_view\u001b[38;5;241m.\u001b[39mattached_dependencies:\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\restore.py:66\u001b[0m, in \u001b[0;36mCheckpointPosition.restore\u001b[1;34m(self, trackable, reader)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_object(trackable):\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# This object's correspondence with a checkpointed object is new, so\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# process deferred restorations for it and its dependencies.\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     restore_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_descendants\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m restore_ops:\n\u001b[0;32m     68\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint\u001b[38;5;241m.\u001b[39mnew_restore_ops(restore_ops)\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\restore.py:533\u001b[0m, in \u001b[0;36mCheckpointPosition._restore_descendants\u001b[1;34m(self, reader)\u001b[0m\n\u001b[0;32m    529\u001b[0m   _queue_children_for_restoration(current_position, visit_queue)\n\u001b[0;32m    530\u001b[0m   _queue_slot_variables(current_position, visit_queue)\n\u001b[0;32m    532\u001b[0m restore_ops\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m--> 533\u001b[0m     \u001b[43mcurrent_position\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_saveables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_saveables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpython_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistered_savers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreader\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m )\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:384\u001b[0m, in \u001b[0;36m_CheckpointRestoreCoordinator.restore_saveables\u001b[1;34m(self, tensor_saveables, python_positions, registered_savers, reader)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor_saveables \u001b[38;5;129;01mor\u001b[39;00m registered_savers:\n\u001b[0;32m    380\u001b[0m   flat_saveables \u001b[38;5;241m=\u001b[39m saveable_object_util\u001b[38;5;241m.\u001b[39mvalidate_and_slice_inputs(\n\u001b[0;32m    381\u001b[0m       tensor_saveables)\n\u001b[0;32m    382\u001b[0m   new_restore_ops \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiDeviceSaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_saveables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflat_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 384\u001b[0m \u001b[43m      \u001b[49m\u001b[43mregistered_savers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_path_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, restore_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(new_restore_ops\u001b[38;5;241m.\u001b[39mitems()):\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:658\u001b[0m, in \u001b[0;36mMultiDeviceSaver.restore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    656\u001b[0m   restore_ops \u001b[38;5;241m=\u001b[39m tf_function_restore()\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 658\u001b[0m   restore_ops \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:590\u001b[0m, in \u001b[0;36mMultiDeviceSaver.restore.<locals>.restore_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task, shard \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shardable_tensors_by_task\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    588\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(task):\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;66;03m# Load values from checkpoint\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     restored_tensor_dict \u001b[38;5;241m=\u001b[39m \u001b[43m_single_shard_restore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;66;03m# Map restored tensors to the corresponding restore_fn, and see if\u001b[39;00m\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# all inputs have all been loaded. Call `restore_fn` if that is the\u001b[39;00m\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# case.\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ckpt_key, slice_and_tensor \u001b[38;5;129;01min\u001b[39;00m restored_tensor_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:138\u001b[0m, in \u001b[0;36m_single_shard_restore\u001b[1;34m(file_prefix, shardable_tensors, options)\u001b[0m\n\u001b[0;32m    136\u001b[0m restore_device \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mexperimental_io_device \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(restore_device):\n\u001b[1;32m--> 138\u001b[0m   restored_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mio_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_specs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_dtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m restored_tensor_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shardable_tensor \u001b[38;5;129;01min\u001b[39;00m shardable_tensors:\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:1599\u001b[0m, in \u001b[0;36mrestore_v2\u001b[1;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[0;32m   1597\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrestore_v2_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1600\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_and_slices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1601\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m   1603\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:1638\u001b[0m, in \u001b[0;36mrestore_v2_eager_fallback\u001b[1;34m(prefix, tensor_names, shape_and_slices, dtypes, name, ctx)\u001b[0m\n\u001b[0;32m   1636\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [prefix, tensor_names, shape_and_slices]\n\u001b[0;32m   1637\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtypes)\n\u001b[1;32m-> 1638\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRestoreV2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[0;32m   1641\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[0;32m   1642\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestoreV2\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32md:\\kim\\TensorFlow\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "EPOCHS = 10\n",
    " \n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    " \n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    " \n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    " \n",
    "    if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "  if (epoch + 1) % 2 == 0:  # 2 에포크마다 모델을 체크포인트에 저장\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    " \n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 함수\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    " \n",
    "    sentence = preprocess_sentence(sentence)\n",
    " \n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    " \n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))  # 어텐션 가중치\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)    # 예측된 ID가 모델에 피드백\n",
    " \n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 가중치 시각화를 위한 함수 정의\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역을 위한 함수 정의 및 번역 문장 입력 함수\n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    " \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    " \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' ')) #어텐션 가중치 매핑\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))  #1\n",
    "\n",
    "translate(u'esta es mi vida.')   # 스페인어를 영어로 번역"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
